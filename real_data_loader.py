"""
çœŸå¯¦æ•¸æ“šåŠ è¼‰å™¨
Real Data Loader for Pricing Analysis
"""

import pandas as pd
import numpy as np
from typing import Optional, Dict, List, Union
import warnings
from pathlib import Path

class RealDataLoader:
    """çœŸå¯¦æ•¸æ“šåŠ è¼‰å’Œé è™•ç†é¡"""
    
    def __init__(self):
        self.data = None
        self.data_info = {}
        self.required_columns = {
            'price': 'åƒ¹æ ¼',
            'sales_volume': 'éŠ·é‡',
            'date': 'æ—¥æœŸ',
            'customer_id': 'å®¢æˆ¶IDï¼ˆå¯é¸ï¼‰',
            'product_id': 'ç”¢å“IDï¼ˆå¯é¸ï¼‰'
        }
    
    def load_csv_data(self, file_path: str, **kwargs) -> pd.DataFrame:
        """
        å¾CSVæ–‡ä»¶åŠ è¼‰æ•¸æ“š
        
        Parameters:
        -----------
        file_path : str
            CSVæ–‡ä»¶è·¯å¾‘
        **kwargs : dict
            pandas.read_csvçš„å…¶ä»–åƒæ•¸
        
        Returns:
        --------
        pd.DataFrame
            åŠ è¼‰çš„æ•¸æ“š
        """
        try:
            # å˜—è©¦ä¸åŒçš„ç·¨ç¢¼
            encodings = ['utf-8', 'gbk', 'gb2312', 'big5', 'latin1']
            
            for encoding in encodings:
                try:
                    data = pd.read_csv(file_path, encoding=encoding, **kwargs)
                    print(f"âœ… æˆåŠŸä½¿ç”¨ {encoding} ç·¨ç¢¼åŠ è¼‰æ•¸æ“š")
                    break
                except UnicodeDecodeError:
                    continue
            else:
                raise ValueError("ç„¡æ³•ä½¿ç”¨å¸¸è¦‹ç·¨ç¢¼è®€å–æ–‡ä»¶ï¼Œè«‹æª¢æŸ¥æ–‡ä»¶æ ¼å¼")
            
            self.data = data
            self._analyze_data_structure()
            return data
            
        except Exception as e:
            print(f"âŒ åŠ è¼‰æ•¸æ“šå¤±æ•—: {e}")
            raise
    
    def load_excel_data(self, file_path: str, sheet_name: Union[str, int] = 0, **kwargs) -> pd.DataFrame:
        """
        å¾Excelæ–‡ä»¶åŠ è¼‰æ•¸æ“š
        
        Parameters:
        -----------
        file_path : str
            Excelæ–‡ä»¶è·¯å¾‘
        sheet_name : str or int
            å·¥ä½œè¡¨åç¨±æˆ–ç´¢å¼•
        **kwargs : dict
            pandas.read_excelçš„å…¶ä»–åƒæ•¸
        
        Returns:
        --------
        pd.DataFrame
            åŠ è¼‰çš„æ•¸æ“š
        """
        try:
            data = pd.read_excel(file_path, sheet_name=sheet_name, **kwargs)
            self.data = data
            self._analyze_data_structure()
            print(f"âœ… æˆåŠŸå¾ExcelåŠ è¼‰æ•¸æ“šï¼Œå·¥ä½œè¡¨: {sheet_name}")
            return data
            
        except Exception as e:
            print(f"âŒ åŠ è¼‰Excelæ•¸æ“šå¤±æ•—: {e}")
            raise
    
    def _analyze_data_structure(self):
        """åˆ†ææ•¸æ“šçµæ§‹"""
        if self.data is None:
            return
        
        self.data_info = {
            'shape': self.data.shape,
            'columns': list(self.data.columns),
            'dtypes': dict(self.data.dtypes),
            'missing_values': dict(self.data.isnull().sum()),
            'numeric_columns': list(self.data.select_dtypes(include=[np.number]).columns),
            'categorical_columns': list(self.data.select_dtypes(include=['object']).columns),
            'date_columns': []
        }
        
        # æª¢æ¸¬å¯èƒ½çš„æ—¥æœŸåˆ—
        for col in self.data.columns:
            if any(keyword in col.lower() for keyword in ['date', 'æ—¥æœŸ', 'time', 'æ™‚é–“']):
                self.data_info['date_columns'].append(col)
        
        print(f"ğŸ“Š æ•¸æ“šæ¦‚æ³:")
        print(f"   - å½¢ç‹€: {self.data_info['shape']}")
        print(f"   - æ•¸å€¼åˆ—: {len(self.data_info['numeric_columns'])} å€‹")
        print(f"   - åˆ†é¡åˆ—: {len(self.data_info['categorical_columns'])} å€‹")
        print(f"   - ç¼ºå¤±å€¼: {sum(self.data_info['missing_values'].values())} å€‹")
    
    def suggest_column_mapping(self) -> Dict[str, List[str]]:
        """å»ºè­°åˆ—åæ˜ å°„"""
        suggestions = {}
        
        # åƒ¹æ ¼ç›¸é—œåˆ—
        price_keywords = ['price', 'åƒ¹æ ¼', 'cost', 'æˆæœ¬', 'amount', 'é‡‘é¡', 'å–®åƒ¹']
        suggestions['price'] = [col for col in self.data.columns 
                               if any(keyword in col.lower() for keyword in price_keywords)]
        
        # éŠ·é‡ç›¸é—œåˆ—
        volume_keywords = ['volume', 'éŠ·é‡', 'quantity', 'æ•¸é‡', 'sales', 'éŠ·å”®', 'sold', 'å”®å‡º']
        suggestions['sales_volume'] = [col for col in self.data.columns 
                                     if any(keyword in col.lower() for keyword in volume_keywords)]
        
        # æ—¥æœŸç›¸é—œåˆ—
        date_keywords = ['date', 'æ—¥æœŸ', 'time', 'æ™‚é–“', 'day', 'å¤©']
        suggestions['date'] = [col for col in self.data.columns 
                              if any(keyword in col.lower() for keyword in date_keywords)]
        
        # å®¢æˆ¶ç›¸é—œåˆ—
        customer_keywords = ['customer', 'å®¢æˆ¶', 'user', 'ç”¨æˆ¶', 'client', 'å®¢æˆ¶ç«¯']
        suggestions['customer_id'] = [col for col in self.data.columns 
                                    if any(keyword in col.lower() for keyword in customer_keywords)]
        
        # ç”¢å“ç›¸é—œåˆ—
        product_keywords = ['product', 'ç”¢å“', 'item', 'å•†å“', 'sku', 'goods']
        suggestions['product_id'] = [col for col in self.data.columns 
                                   if any(keyword in col.lower() for keyword in product_keywords)]
        
        return suggestions
    
    def map_columns(self, column_mapping: Dict[str, str]) -> pd.DataFrame:
        """
        æ˜ å°„åˆ—ååˆ°æ¨™æº–æ ¼å¼
        
        Parameters:
        -----------
        column_mapping : dict
            åˆ—åæ˜ å°„å­—å…¸ï¼Œä¾‹å¦‚ {'åŸåˆ—å': 'æ¨™æº–åˆ—å'}
        
        Returns:
        --------
        pd.DataFrame
            æ˜ å°„å¾Œçš„æ•¸æ“š
        """
        if self.data is None:
            raise ValueError("è«‹å…ˆåŠ è¼‰æ•¸æ“š")
        
        # å‰µå»ºæ•¸æ“šå‰¯æœ¬
        mapped_data = self.data.copy()
        
        # é‡å‘½ååˆ—
        mapped_data = mapped_data.rename(columns=column_mapping)
        
        # æª¢æŸ¥å¿…éœ€çš„åˆ—
        missing_columns = []
        for col in ['price', 'sales_volume']:
            if col not in mapped_data.columns:
                missing_columns.append(col)
        
        if missing_columns:
            print(f"âš ï¸  ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing_columns}")
            print("è«‹ç¢ºä¿æ•¸æ“šåŒ…å«åƒ¹æ ¼å’ŒéŠ·é‡ä¿¡æ¯")
        
        self.data = mapped_data
        print(f"âœ… åˆ—åæ˜ å°„å®Œæˆ")
        return mapped_data
    
    def preprocess_data(self, 
                       price_col: str = 'price',
                       volume_col: str = 'sales_volume',
                       date_col: Optional[str] = None,
                       customer_col: Optional[str] = None,
                       remove_outliers: bool = True,
                       outlier_method: str = 'iqr') -> pd.DataFrame:
        """
        æ•¸æ“šé è™•ç†
        
        Parameters:
        -----------
        price_col : str
            åƒ¹æ ¼åˆ—å
        volume_col : str
            éŠ·é‡åˆ—å
        date_col : str, optional
            æ—¥æœŸåˆ—å
        customer_col : str, optional
            å®¢æˆ¶åˆ—å
        remove_outliers : bool
            æ˜¯å¦ç§»é™¤ç•°å¸¸å€¼
        outlier_method : str
            ç•°å¸¸å€¼æª¢æ¸¬æ–¹æ³• ('iqr' æˆ– 'zscore')
        
        Returns:
        --------
        pd.DataFrame
            é è™•ç†å¾Œçš„æ•¸æ“š
        """
        if self.data is None:
            raise ValueError("è«‹å…ˆåŠ è¼‰æ•¸æ“š")
        
        processed_data = self.data.copy()
        
        # 1. è™•ç†ç¼ºå¤±å€¼
        print("ğŸ”§ è™•ç†ç¼ºå¤±å€¼...")
        initial_rows = len(processed_data)
        processed_data = processed_data.dropna(subset=[price_col, volume_col])
        removed_rows = initial_rows - len(processed_data)
        if removed_rows > 0:
            print(f"   ç§»é™¤äº† {removed_rows} è¡ŒåŒ…å«ç¼ºå¤±å€¼çš„æ•¸æ“š")
        
        # 2. æ•¸æ“šé¡å‹è½‰æ›
        print("ğŸ”§ è½‰æ›æ•¸æ“šé¡å‹...")
        processed_data[price_col] = pd.to_numeric(processed_data[price_col], errors='coerce')
        processed_data[volume_col] = pd.to_numeric(processed_data[volume_col], errors='coerce')
        
        # 3. è™•ç†æ—¥æœŸåˆ—
        if date_col and date_col in processed_data.columns:
            print("ğŸ”§ è™•ç†æ—¥æœŸæ•¸æ“š...")
            processed_data[date_col] = pd.to_datetime(processed_data[date_col], errors='coerce')
            processed_data = processed_data.dropna(subset=[date_col])
        
        # 4. ç§»é™¤ç•°å¸¸å€¼
        if remove_outliers:
            print(f"ğŸ”§ ä½¿ç”¨ {outlier_method} æ–¹æ³•ç§»é™¤ç•°å¸¸å€¼...")
            processed_data = self._remove_outliers(processed_data, [price_col, volume_col], method=outlier_method)
        
        # 5. åŸºæœ¬æ•¸æ“šé©—è­‰
        print("ğŸ”§ æ•¸æ“šé©—è­‰...")
        # ç§»é™¤è² åƒ¹æ ¼å’Œè² éŠ·é‡
        initial_rows = len(processed_data)
        processed_data = processed_data[
            (processed_data[price_col] > 0) & 
            (processed_data[volume_col] >= 0)
        ]
        removed_rows = initial_rows - len(processed_data)
        if removed_rows > 0:
            print(f"   ç§»é™¤äº† {removed_rows} è¡Œç„¡æ•ˆæ•¸æ“šï¼ˆè² åƒ¹æ ¼æˆ–è² éŠ·é‡ï¼‰")
        
        self.data = processed_data
        print(f"âœ… æ•¸æ“šé è™•ç†å®Œæˆï¼Œæœ€çµ‚æ•¸æ“šå½¢ç‹€: {processed_data.shape}")
        
        return processed_data
    
    def _remove_outliers(self, data: pd.DataFrame, columns: List[str], method: str = 'iqr') -> pd.DataFrame:
        """ç§»é™¤ç•°å¸¸å€¼"""
        cleaned_data = data.copy()
        
        for col in columns:
            if method == 'iqr':
                Q1 = cleaned_data[col].quantile(0.25)
                Q3 = cleaned_data[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                outliers = (cleaned_data[col] < lower_bound) | (cleaned_data[col] > upper_bound)
                
            elif method == 'zscore':
                z_scores = np.abs((cleaned_data[col] - cleaned_data[col].mean()) / cleaned_data[col].std())
                outliers = z_scores > 3
            
            outlier_count = outliers.sum()
            if outlier_count > 0:
                print(f"   {col}: ç§»é™¤äº† {outlier_count} å€‹ç•°å¸¸å€¼")
                cleaned_data = cleaned_data[~outliers]
        
        return cleaned_data
    
    def create_treatment_variable(self, 
                                method: str = 'price_change',
                                threshold: Optional[float] = None,
                                date_col: Optional[str] = None,
                                treatment_date: Optional[str] = None) -> pd.DataFrame:
        """
        å‰µå»ºè™•ç†è®Šæ•¸ï¼ˆå¯¦é©—çµ„/å°ç…§çµ„æ¨™è­˜ï¼‰
        
        Parameters:
        -----------
        method : str
            å‰µå»ºæ–¹æ³• ('price_change', 'median_split', 'date_based', 'random')
        threshold : float, optional
            é–¾å€¼ï¼ˆç”¨æ–¼price_changeæ–¹æ³•ï¼‰
        date_col : str, optional
            æ—¥æœŸåˆ—åï¼ˆç”¨æ–¼date_basedæ–¹æ³•ï¼‰
        treatment_date : str, optional
            è™•ç†é–‹å§‹æ—¥æœŸï¼ˆç”¨æ–¼date_basedæ–¹æ³•ï¼‰
        
        Returns:
        --------
        pd.DataFrame
            åŒ…å«è™•ç†è®Šæ•¸çš„æ•¸æ“š
        """
        if self.data is None:
            raise ValueError("è«‹å…ˆåŠ è¼‰å’Œé è™•ç†æ•¸æ“š")
        
        data_with_treatment = self.data.copy()
        
        if method == 'price_change':
            # åŸºæ–¼åƒ¹æ ¼è®ŠåŒ–å‰µå»ºè™•ç†è®Šæ•¸
            if 'price' not in data_with_treatment.columns:
                raise ValueError("æ•¸æ“šä¸­æ²’æœ‰æ‰¾åˆ°priceåˆ—")
            
            if threshold is None:
                threshold = data_with_treatment['price'].median()
            
            data_with_treatment['price_treatment'] = (data_with_treatment['price'] < threshold).astype(int)
            print(f"âœ… åŸºæ–¼åƒ¹æ ¼é–¾å€¼ {threshold:.2f} å‰µå»ºè™•ç†è®Šæ•¸")
            
        elif method == 'median_split':
            # åŸºæ–¼åƒ¹æ ¼ä¸­ä½æ•¸åˆ†çµ„
            median_price = data_with_treatment['price'].median()
            data_with_treatment['price_treatment'] = (data_with_treatment['price'] < median_price).astype(int)
            print(f"âœ… åŸºæ–¼åƒ¹æ ¼ä¸­ä½æ•¸ {median_price:.2f} å‰µå»ºè™•ç†è®Šæ•¸")
            
        elif method == 'date_based':
            # åŸºæ–¼æ—¥æœŸå‰µå»ºè™•ç†è®Šæ•¸
            if date_col is None or date_col not in data_with_treatment.columns:
                raise ValueError("date_basedæ–¹æ³•éœ€è¦æŒ‡å®šæœ‰æ•ˆçš„æ—¥æœŸåˆ—")
            
            if treatment_date is None:
                raise ValueError("date_basedæ–¹æ³•éœ€è¦æŒ‡å®štreatment_date")
            
            treatment_date = pd.to_datetime(treatment_date)
            data_with_treatment['price_treatment'] = (data_with_treatment[date_col] >= treatment_date).astype(int)
            print(f"âœ… åŸºæ–¼æ—¥æœŸ {treatment_date} å‰µå»ºè™•ç†è®Šæ•¸")
            
        elif method == 'random':
            # éš¨æ©Ÿåˆ†çµ„
            np.random.seed(42)
            data_with_treatment['price_treatment'] = np.random.binomial(1, 0.5, len(data_with_treatment))
            print("âœ… éš¨æ©Ÿå‰µå»ºè™•ç†è®Šæ•¸")
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–¹æ³•: {method}")
        
        # é¡¯ç¤ºåˆ†çµ„çµ±è¨ˆ
        treatment_counts = data_with_treatment['price_treatment'].value_counts()
        print(f"   è™•ç†çµ„åˆ†ä½ˆ: å°ç…§çµ„ {treatment_counts[0]} å€‹, å¯¦é©—çµ„ {treatment_counts[1]} å€‹")
        
        self.data = data_with_treatment
        return data_with_treatment
    
    def add_control_variables(self, 
                            date_col: Optional[str] = None,
                            customer_col: Optional[str] = None,
                            product_col: Optional[str] = None) -> pd.DataFrame:
        """æ·»åŠ æ§åˆ¶è®Šæ•¸"""
        if self.data is None:
            raise ValueError("è«‹å…ˆåŠ è¼‰æ•¸æ“š")
        
        enhanced_data = self.data.copy()
        
        # æ·»åŠ æ™‚é–“ç›¸é—œè®Šæ•¸
        if date_col and date_col in enhanced_data.columns:
            enhanced_data['year'] = enhanced_data[date_col].dt.year
            enhanced_data['month'] = enhanced_data[date_col].dt.month
            enhanced_data['quarter'] = enhanced_data[date_col].dt.quarter
            enhanced_data['weekday'] = enhanced_data[date_col].dt.weekday
            
            # å­£ç¯€è®Šæ•¸
            season_map = {12: 'å†¬', 1: 'å†¬', 2: 'å†¬',
                         3: 'æ˜¥', 4: 'æ˜¥', 5: 'æ˜¥',
                         6: 'å¤', 7: 'å¤', 8: 'å¤',
                         9: 'ç§‹', 10: 'ç§‹', 11: 'ç§‹'}
            enhanced_data['season'] = enhanced_data['month'].map(season_map)
            print("âœ… æ·»åŠ äº†æ™‚é–“ç›¸é—œæ§åˆ¶è®Šæ•¸")
        
        # æ·»åŠ å®¢æˆ¶ç›¸é—œè®Šæ•¸
        if customer_col and customer_col in enhanced_data.columns:
            # å®¢æˆ¶è³¼è²·é »æ¬¡
            customer_freq = enhanced_data[customer_col].value_counts()
            enhanced_data['customer_frequency'] = enhanced_data[customer_col].map(customer_freq)
            
            # å®¢æˆ¶åˆ†çµ„ï¼ˆåŸºæ–¼è³¼è²·é »æ¬¡ï¼‰
            freq_quantiles = enhanced_data['customer_frequency'].quantile([0.33, 0.67])
            enhanced_data['customer_segment'] = pd.cut(
                enhanced_data['customer_frequency'],
                bins=[0, freq_quantiles[0.33], freq_quantiles[0.67], float('inf')],
                labels=['ä½ç«¯', 'ä¸­ç«¯', 'é«˜ç«¯']
            )
            print("âœ… æ·»åŠ äº†å®¢æˆ¶ç›¸é—œæ§åˆ¶è®Šæ•¸")
        
        # æ·»åŠ ç”¢å“ç›¸é—œè®Šæ•¸
        if product_col and product_col in enhanced_data.columns:
            # ç”¢å“å¹³å‡åƒ¹æ ¼
            product_avg_price = enhanced_data.groupby(product_col)['price'].mean()
            enhanced_data['product_avg_price'] = enhanced_data[product_col].map(product_avg_price)
            
            # ç”¢å“åƒ¹æ ¼ç›¸å°ä½ç½®
            enhanced_data['price_relative'] = enhanced_data['price'] / enhanced_data['product_avg_price']
            print("âœ… æ·»åŠ äº†ç”¢å“ç›¸é—œæ§åˆ¶è®Šæ•¸")
        
        self.data = enhanced_data
        return enhanced_data
    
    def export_processed_data(self, file_path: str, format: str = 'csv'):
        """å°å‡ºè™•ç†å¾Œçš„æ•¸æ“š"""
        if self.data is None:
            raise ValueError("æ²’æœ‰æ•¸æ“šå¯ä»¥å°å‡º")
        
        if format.lower() == 'csv':
            self.data.to_csv(file_path, index=False, encoding='utf-8-sig')
        elif format.lower() == 'excel':
            self.data.to_excel(file_path, index=False)
        else:
            raise ValueError("æ”¯æŒçš„æ ¼å¼: 'csv' æˆ– 'excel'")
        
        print(f"âœ… æ•¸æ“šå·²å°å‡ºåˆ°: {file_path}")
    
    def get_data_summary(self) -> Dict:
        """ç²å–æ•¸æ“šæ‘˜è¦"""
        if self.data is None:
            return {}
        
        summary = {
            'basic_info': {
                'shape': self.data.shape,
                'columns': list(self.data.columns),
                'memory_usage': f"{self.data.memory_usage(deep=True).sum() / 1024**2:.2f} MB"
            },
            'numeric_summary': {},
            'categorical_summary': {}
        }
        
        # æ•¸å€¼è®Šæ•¸æ‘˜è¦
        numeric_cols = self.data.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            summary['numeric_summary'][col] = {
                'mean': self.data[col].mean(),
                'median': self.data[col].median(),
                'std': self.data[col].std(),
                'min': self.data[col].min(),
                'max': self.data[col].max(),
                'missing': self.data[col].isnull().sum()
            }
        
        # åˆ†é¡è®Šæ•¸æ‘˜è¦
        categorical_cols = self.data.select_dtypes(include=['object', 'category']).columns
        for col in categorical_cols:
            summary['categorical_summary'][col] = {
                'unique_count': self.data[col].nunique(),
                'top_values': self.data[col].value_counts().head().to_dict(),
                'missing': self.data[col].isnull().sum()
            }
        
        return summary

def create_sample_real_data():
    """å‰µå»ºç¤ºä¾‹çœŸå¯¦æ•¸æ“šæ ¼å¼"""
    np.random.seed(42)
    
    # æ¨¡æ“¬é›»å•†æ•¸æ“š
    n_records = 5000
    start_date = pd.to_datetime('2023-01-01')
    end_date = pd.to_datetime('2023-12-31')
    
    data = {
        'è¨‚å–®æ—¥æœŸ': pd.date_range(start_date, end_date, periods=n_records),
        'ç”¢å“ID': np.random.choice(['P001', 'P002', 'P003', 'P004', 'P005'], n_records),
        'å®¢æˆ¶ID': np.random.choice(range(1, 1001), n_records),
        'éŠ·å”®åƒ¹æ ¼': np.random.normal(100, 25, n_records),
        'éŠ·å”®æ•¸é‡': np.random.poisson(5, n_records),
        'ä¿ƒéŠ·æ´»å‹•': np.random.choice(['ç„¡', 'æ»¿æ¸›', 'æŠ˜æ‰£', 'VIP'], n_records),
        'éŠ·å”®æ¸ é“': np.random.choice(['ç·šä¸Š', 'ç·šä¸‹', 'ç§»å‹•ç«¯'], n_records),
        'åœ°å€': np.random.choice(['åŒ—äº¬', 'ä¸Šæµ·', 'å»£å·', 'æ·±åœ³', 'æ­å·'], n_records)
    }
    
    df = pd.DataFrame(data)
    
    # ç¢ºä¿åƒ¹æ ¼å’Œæ•¸é‡ç‚ºæ­£æ•¸
    df['éŠ·å”®åƒ¹æ ¼'] = np.abs(df['éŠ·å”®åƒ¹æ ¼'])
    df['éŠ·å”®æ•¸é‡'] = np.abs(df['éŠ·å”®æ•¸é‡'])
    
    # æ·»åŠ ä¸€äº›æ¥­å‹™é‚è¼¯
    df.loc[df['ä¿ƒéŠ·æ´»å‹•'] == 'æŠ˜æ‰£', 'éŠ·å”®åƒ¹æ ¼'] *= 0.8
    df.loc[df['ä¿ƒéŠ·æ´»å‹•'] == 'VIP', 'éŠ·å”®åƒ¹æ ¼'] *= 0.9
    
    return df

if __name__ == "__main__":
    # å‰µå»ºç¤ºä¾‹æ•¸æ“š
    sample_data = create_sample_real_data()
    sample_data.to_csv('sample_pricing_data.csv', index=False, encoding='utf-8-sig')
    print("âœ… å‰µå»ºäº†ç¤ºä¾‹æ•¸æ“šæ–‡ä»¶: sample_pricing_data.csv")
    
    # æ¼”ç¤ºæ•¸æ“šåŠ è¼‰æµç¨‹
    loader = RealDataLoader()
    
    # åŠ è¼‰æ•¸æ“š
    data = loader.load_csv_data('sample_pricing_data.csv')
    
    # å»ºè­°åˆ—åæ˜ å°„
    suggestions = loader.suggest_column_mapping()
    print("\nğŸ“‹ å»ºè­°çš„åˆ—åæ˜ å°„:")
    for key, values in suggestions.items():
        if values:
            print(f"   {key}: {values}")
    
    # æ˜ å°„åˆ—å
    column_mapping = {
        'éŠ·å”®åƒ¹æ ¼': 'price',
        'éŠ·å”®æ•¸é‡': 'sales_volume',
        'è¨‚å–®æ—¥æœŸ': 'date',
        'å®¢æˆ¶ID': 'customer_id',
        'ç”¢å“ID': 'product_id'
    }
    
    mapped_data = loader.map_columns(column_mapping)
    
    # é è™•ç†æ•¸æ“š
    processed_data = loader.preprocess_data(
        price_col='price',
        volume_col='sales_volume',
        date_col='date',
        customer_col='customer_id'
    )
    
    # å‰µå»ºè™•ç†è®Šæ•¸
    final_data = loader.create_treatment_variable(method='median_split')
    
    # æ·»åŠ æ§åˆ¶è®Šæ•¸
    enhanced_data = loader.add_control_variables(
        date_col='date',
        customer_col='customer_id',
        product_col='product_id'
    )
    
    print(f"\nâœ… æœ€çµ‚æ•¸æ“šå½¢ç‹€: {enhanced_data.shape}")
    print(f"âœ… åˆ—å: {list(enhanced_data.columns)}")