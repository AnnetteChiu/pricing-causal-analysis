"""
çœŸå¯¦æ•¸æ“šå®šåƒ¹ç­–ç•¥å› æœæ¨è«–åˆ†æ
Real Data Pricing Strategy Causal Analysis
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pricing_causal_analysis import PricingCausalAnalysis
from real_data_loader import RealDataLoader, create_sample_real_data

# è¨­ç½®ä¸­æ–‡å­—é«”
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False

def analyze_real_data(data_source, column_mapping=None):
    """
    åˆ†æçœŸå¯¦æ•¸æ“šçš„å®Œæ•´æµç¨‹
    
    Parameters:
    -----------
    data_source : str or pd.DataFrame
        æ•¸æ“šæº
    column_mapping : dict, optional
        åˆ—åæ˜ å°„å­—å…¸
    """
    
    print("ğŸš€ é–‹å§‹çœŸå¯¦æ•¸æ“šå®šåƒ¹ç­–ç•¥å› æœæ¨è«–åˆ†æ")
    print("=" * 60)
    
    # ç¬¬ä¸€æ­¥ï¼šæ•¸æ“šåŠ è¼‰å’Œé è™•ç†
    print("\nğŸ“Š ç¬¬ä¸€æ­¥ï¼šæ•¸æ“šåŠ è¼‰å’Œé è™•ç†")
    print("-" * 30)
    
    loader = RealDataLoader()
    
    # åŠ è¼‰æ•¸æ“š
    if isinstance(data_source, str):
        if data_source.endswith('.csv'):
            raw_data = loader.load_csv_data(data_source)
        elif data_source.endswith(('.xlsx', '.xls')):
            raw_data = loader.load_excel_data(data_source)
        else:
            raise ValueError("æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: .csv, .xlsx, .xls")
    else:
        raw_data = data_source
        loader.data = raw_data
        loader._analyze_data_structure()
    
    # å»ºè­°åˆ—åæ˜ å°„
    if column_mapping is None:
        print("\nğŸ’¡ å»ºè­°çš„åˆ—åæ˜ å°„:")
        suggestions = loader.suggest_column_mapping()
        for key, values in suggestions.items():
            if values:
                print(f"   {key}: {values}")
        
        # è‡ªå‹•é¸æ“‡æœ€å¯èƒ½çš„åˆ—å
        auto_mapping = {}
        for key, values in suggestions.items():
            if values:
                auto_mapping[values[0]] = key
        
        if auto_mapping:
            print(f"\nğŸ¤– è‡ªå‹•é¸æ“‡çš„æ˜ å°„: {auto_mapping}")
            column_mapping = auto_mapping
        else:
            print("âš ï¸  ç„¡æ³•è‡ªå‹•è­˜åˆ¥åˆ—åï¼Œè«‹æ‰‹å‹•æŒ‡å®šcolumn_mappingåƒæ•¸")
            return None
    
    # æ˜ å°„åˆ—å
    if column_mapping:
        mapped_data = loader.map_columns(column_mapping)
    else:
        mapped_data = raw_data
    
    # æ•¸æ“šé è™•ç†
    processed_data = loader.preprocess_data(
        price_col='price',
        volume_col='sales_volume',
        date_col='date' if 'date' in mapped_data.columns else None,
        customer_col='customer_id' if 'customer_id' in mapped_data.columns else None,
        remove_outliers=True
    )
    
    # å‰µå»ºè™•ç†è®Šæ•¸
    if 'price_treatment' not in processed_data.columns:
        print("\nğŸ¯ å‰µå»ºè™•ç†è®Šæ•¸...")
        final_data = loader.create_treatment_variable(
            method='median_split'  # åŸºæ–¼åƒ¹æ ¼ä¸­ä½æ•¸åˆ†çµ„
        )
    else:
        final_data = processed_data
        print("âœ… æ•¸æ“šä¸­å·²åŒ…å«è™•ç†è®Šæ•¸")
    
    # æ·»åŠ æ§åˆ¶è®Šæ•¸
    enhanced_data = loader.add_control_variables(
        date_col='date' if 'date' in final_data.columns else None,
        customer_col='customer_id' if 'customer_id' in final_data.columns else None,
        product_col='product_id' if 'product_id' in final_data.columns else None
    )
    
    # ç¬¬äºŒæ­¥ï¼šå› æœæ¨è«–åˆ†æ
    print("\nğŸ”¬ ç¬¬äºŒæ­¥ï¼šå› æœæ¨è«–åˆ†æ")
    print("-" * 30)
    
    # å‰µå»ºåˆ†æå™¨ä¸¦åŠ è¼‰æ•¸æ“š
    analyzer = PricingCausalAnalysis(data=enhanced_data)
    
    # åŸ·è¡Œå„ç¨®åˆ†æ
    print("åŸ·è¡Œéš¨æ©Ÿå¯¦é©—åˆ†æ...")
    analyzer.randomized_experiment_analysis()
    
    print("åŸ·è¡Œå›æ­¸èª¿æ•´åˆ†æ...")
    analyzer.regression_adjustment_analysis()
    
    print("åŸ·è¡Œå‚¾å‘å¾—åˆ†åˆ†æ...")
    analyzer.propensity_score_analysis()
    
    if len(enhanced_data['customer_segment'].unique()) > 1:
        print("åŸ·è¡Œåƒ¹æ ¼å½ˆæ€§åˆ†æ...")
        analyzer.price_elasticity_analysis()
    
    # ç¬¬ä¸‰æ­¥ï¼šçµæœå¯è¦–åŒ–
    print("\nğŸ“ˆ ç¬¬ä¸‰æ­¥ï¼šçµæœå¯è¦–åŒ–")
    print("-" * 30)
    
    create_real_data_visualization(analyzer, enhanced_data)
    
    # ç¬¬å››æ­¥ï¼šç”Ÿæˆå ±å‘Š
    print("\nğŸ“‹ ç¬¬å››æ­¥ï¼šåˆ†æå ±å‘Š")
    print("-" * 30)
    
    generate_real_data_report(analyzer, enhanced_data, loader)
    
    return analyzer, enhanced_data

def create_real_data_visualization(analyzer, data):
    """å‰µå»ºçœŸå¯¦æ•¸æ“šçš„å¯è¦–åŒ–"""
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('çœŸå¯¦æ•¸æ“šå®šåƒ¹ç­–ç•¥å› æœæ¨è«–åˆ†æçµæœ', fontsize=16)
    
    # 1. åƒ¹æ ¼åˆ†ä½ˆå°æ¯”
    treatment_data = data[data['price_treatment'] == 1]
    control_data = data[data['price_treatment'] == 0]
    
    axes[0, 0].hist(control_data['price'], alpha=0.7, label='å°ç…§çµ„', bins=30, color='lightblue')
    axes[0, 0].hist(treatment_data['price'], alpha=0.7, label='å¯¦é©—çµ„', bins=30, color='lightcoral')
    axes[0, 0].set_title('åƒ¹æ ¼åˆ†ä½ˆå°æ¯”')
    axes[0, 0].set_xlabel('åƒ¹æ ¼')
    axes[0, 0].set_ylabel('é »ç‡')
    axes[0, 0].legend()
    
    # 2. éŠ·é‡åˆ†ä½ˆå°æ¯”
    axes[0, 1].hist(control_data['sales_volume'], alpha=0.7, label='å°ç…§çµ„', bins=30, color='lightblue')
    axes[0, 1].hist(treatment_data['sales_volume'], alpha=0.7, label='å¯¦é©—çµ„', bins=30, color='lightcoral')
    axes[0, 1].set_title('éŠ·é‡åˆ†ä½ˆå°æ¯”')
    axes[0, 1].set_xlabel('éŠ·é‡')
    axes[0, 1].set_ylabel('é »ç‡')
    axes[0, 1].legend()
    
    # 3. åƒ¹æ ¼vséŠ·é‡æ•£é»åœ–
    axes[0, 2].scatter(control_data['price'], control_data['sales_volume'], 
                      alpha=0.5, label='å°ç…§çµ„', s=10, color='blue')
    axes[0, 2].scatter(treatment_data['price'], treatment_data['sales_volume'], 
                      alpha=0.5, label='å¯¦é©—çµ„', s=10, color='red')
    axes[0, 2].set_title('åƒ¹æ ¼ vs éŠ·é‡')
    axes[0, 2].set_xlabel('åƒ¹æ ¼')
    axes[0, 2].set_ylabel('éŠ·é‡')
    axes[0, 2].legend()
    
    # 4. è™•ç†æ•ˆæ‡‰æ¯”è¼ƒ
    methods = ['éš¨æ©Ÿå¯¦é©—', 'å›æ­¸èª¿æ•´', 'å‚¾å‘å¾—åˆ†åŒ¹é…']
    effects = [
        analyzer.results.get('experiment_analysis', {}).get('ate_sales', 0),
        analyzer.results.get('regression_analysis', {}).get('treatment_effect', 0),
        analyzer.results.get('propensity_score_analysis', {}).get('ps_ate', 0)
    ]
    
    bars = axes[1, 0].bar(methods, effects, color=['skyblue', 'lightcoral', 'lightgreen'])
    axes[1, 0].set_title('ä¸åŒæ–¹æ³•çš„è™•ç†æ•ˆæ‡‰ä¼°è¨ˆ')
    axes[1, 0].set_ylabel('éŠ·é‡è™•ç†æ•ˆæ‡‰')
    axes[1, 0].tick_params(axis='x', rotation=45)
    
    # æ·»åŠ æ•¸å€¼æ¨™ç±¤
    for bar, effect in zip(bars, effects):
        axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(effects)*0.01,
                       f'{effect:.0f}', ha='center', va='bottom')
    
    # 5. æ™‚é–“è¶¨å‹¢ï¼ˆå¦‚æœæœ‰æ—¥æœŸæ•¸æ“šï¼‰
    if 'date' in data.columns:
        daily_sales = data.groupby(['date', 'price_treatment'])['sales_volume'].mean().unstack()
        if daily_sales.shape[0] > 1:  # ç¢ºä¿æœ‰å¤šå€‹æ™‚é–“é»
            daily_sales.plot(ax=axes[1, 1], title='éŠ·é‡æ™‚é–“è¶¨å‹¢')
            axes[1, 1].set_xlabel('æ—¥æœŸ')
            axes[1, 1].set_ylabel('å¹³å‡éŠ·é‡')
            axes[1, 1].legend(['å°ç…§çµ„', 'å¯¦é©—çµ„'])
        else:
            axes[1, 1].text(0.5, 0.5, 'æ•¸æ“šæ™‚é–“è·¨åº¦ä¸è¶³\nç„¡æ³•é¡¯ç¤ºè¶¨å‹¢', 
                           ha='center', va='center', transform=axes[1, 1].transAxes)
            axes[1, 1].set_title('éŠ·é‡æ™‚é–“è¶¨å‹¢')
    else:
        axes[1, 1].text(0.5, 0.5, 'ç„¡æ—¥æœŸæ•¸æ“š', ha='center', va='center', 
                       transform=axes[1, 1].transAxes)
        axes[1, 1].set_title('éŠ·é‡æ™‚é–“è¶¨å‹¢')
    
    # 6. å®¢æˆ¶ç¾¤é«”åˆ†æï¼ˆå¦‚æœæœ‰å®¢æˆ¶åˆ†ç¾¤æ•¸æ“šï¼‰
    if 'customer_segment' in data.columns and len(data['customer_segment'].unique()) > 1:
        segment_data = data.groupby(['customer_segment', 'price_treatment'])['sales_volume'].mean().unstack()
        segment_data.plot(kind='bar', ax=axes[1, 2])
        axes[1, 2].set_title('ä¸åŒå®¢æˆ¶ç¾¤é«”éŠ·é‡å°æ¯”')
        axes[1, 2].set_xlabel('å®¢æˆ¶ç¾¤é«”')
        axes[1, 2].set_ylabel('å¹³å‡éŠ·é‡')
        axes[1, 2].legend(['å°ç…§çµ„', 'å¯¦é©—çµ„'])
        axes[1, 2].tick_params(axis='x', rotation=45)
    else:
        axes[1, 2].text(0.5, 0.5, 'ç„¡å®¢æˆ¶åˆ†ç¾¤æ•¸æ“š', ha='center', va='center', 
                       transform=axes[1, 2].transAxes)
        axes[1, 2].set_title('å®¢æˆ¶ç¾¤é«”åˆ†æ')
    
    plt.tight_layout()
    plt.show()

def generate_real_data_report(analyzer, data, loader):
    """ç”ŸæˆçœŸå¯¦æ•¸æ“šåˆ†æå ±å‘Š"""
    
    print("\n" + "="*60)
    print("çœŸå¯¦æ•¸æ“šå®šåƒ¹ç­–ç•¥å› æœæ¨è«–åˆ†æå ±å‘Š")
    print("="*60)
    
    # æ•¸æ“šæ¦‚æ³
    print(f"\nğŸ“Š æ•¸æ“šæ¦‚æ³:")
    print(f"   - ç¸½æ¨£æœ¬æ•¸: {len(data):,}")
    print(f"   - æ™‚é–“è·¨åº¦: {data['date'].min()} åˆ° {data['date'].max()}" if 'date' in data.columns else "   - ç„¡æ™‚é–“ä¿¡æ¯")
    print(f"   - å¯¦é©—çµ„æ¯”ä¾‹: {data['price_treatment'].mean():.1%}")
    print(f"   - å¹³å‡åƒ¹æ ¼: ${data['price'].mean():.2f}")
    print(f"   - å¹³å‡éŠ·é‡: {data['sales_volume'].mean():.0f}")
    
    # ä¸»è¦ç™¼ç¾
    print(f"\nğŸ” ä¸»è¦ç™¼ç¾:")
    if 'experiment_analysis' in analyzer.results:
        ate = analyzer.results['experiment_analysis']['ate_sales']
        p_val = analyzer.results['experiment_analysis']['p_value']
        significance = "é¡¯è‘—" if p_val < 0.05 else "ä¸é¡¯è‘—"
        
        price_diff = data[data['price_treatment']==1]['price'].mean() - data[data['price_treatment']==0]['price'].mean()
        if price_diff < 0:
            print(f"   - é™åƒ¹ç­–ç•¥ä½¿éŠ·é‡å¢åŠ  {ate:.0f} å–®ä½ ({significance}, p={p_val:.4f})")
        else:
            print(f"   - æåƒ¹ç­–ç•¥ä½¿éŠ·é‡è®ŠåŒ– {ate:.0f} å–®ä½ ({significance}, p={p_val:.4f})")
    
    # åƒ¹æ ¼å½ˆæ€§åˆ†æ
    if 'price_elasticity' in analyzer.results:
        print(f"\nğŸ’° åƒ¹æ ¼å½ˆæ€§åˆ†æ:")
        for segment, elasticity in analyzer.results['price_elasticity'].items():
            sensitivity = "é«˜åº¦æ•æ„Ÿ" if abs(elasticity) > 2 else "ä¸­åº¦æ•æ„Ÿ" if abs(elasticity) > 1 else "ä½åº¦æ•æ„Ÿ"
            print(f"   - {segment}: {sensitivity} (å½ˆæ€§ä¿‚æ•¸: {elasticity:.3f})")
    
    # æ•¸æ“šè³ªé‡è©•ä¼°
    print(f"\nğŸ“‹ æ•¸æ“šè³ªé‡è©•ä¼°:")
    missing_rate = data.isnull().sum().sum() / (len(data) * len(data.columns))
    print(f"   - ç¼ºå¤±å€¼æ¯”ä¾‹: {missing_rate:.2%}")
    
    if 'customer_id' in data.columns:
        repeat_customers = data['customer_id'].value_counts()
        print(f"   - é‡è¤‡å®¢æˆ¶æ¯”ä¾‹: {(repeat_customers > 1).mean():.1%}")
    
    if 'date' in data.columns:
        date_range = (data['date'].max() - data['date'].min()).days
        print(f"   - æ•¸æ“šæ™‚é–“è·¨åº¦: {date_range} å¤©")
    
    # æ¥­å‹™å»ºè­°
    print(f"\nğŸ’¡ æ¥­å‹™å»ºè­°:")
    
    # åŸºæ–¼è™•ç†æ•ˆæ‡‰çš„å»ºè­°
    if 'experiment_analysis' in analyzer.results:
        ate = analyzer.results['experiment_analysis']['ate_sales']
        p_val = analyzer.results['experiment_analysis']['p_value']
        
        if p_val < 0.05:
            if ate > 0:
                print("   - âœ… ç•¶å‰å®šåƒ¹ç­–ç•¥æœ‰æ•ˆï¼Œå»ºè­°ç¹¼çºŒåŸ·è¡Œ")
                print("   - ğŸ“ˆ å¯ä»¥è€ƒæ…®æ“´å¤§å¯¦æ–½ç¯„åœ")
            else:
                print("   - âš ï¸  ç•¶å‰å®šåƒ¹ç­–ç•¥å¯èƒ½ä¸åˆ©æ–¼éŠ·é‡")
                print("   - ğŸ”„ å»ºè­°é‡æ–°è©•ä¼°å®šåƒ¹ç­–ç•¥")
        else:
            print("   - ğŸ“Š å®šåƒ¹æ•ˆæœä¸æ˜é¡¯ï¼Œéœ€è¦æ›´å¤šæ•¸æ“šæˆ–èª¿æ•´ç­–ç•¥")
    
    # åŸºæ–¼åƒ¹æ ¼å½ˆæ€§çš„å»ºè­°
    if 'price_elasticity' in analyzer.results:
        avg_elasticity = np.mean(list(analyzer.results['price_elasticity'].values()))
        if abs(avg_elasticity) < 1:
            print("   - ğŸ’ å®¢æˆ¶å°åƒ¹æ ¼ä¸æ•æ„Ÿï¼Œæœ‰æåƒ¹ç©ºé–“")
        else:
            print("   - âš¡ å®¢æˆ¶å°åƒ¹æ ¼æ•æ„Ÿï¼Œéœ€è¬¹æ…èª¿åƒ¹")
    
    print(f"\nğŸ“ˆ å¾ŒçºŒå»ºè­°:")
    print("   - æŒçºŒæ”¶é›†æ›´å¤šæ•¸æ“šä»¥æé«˜åˆ†æç²¾åº¦")
    print("   - è€ƒæ…®é€²è¡Œæ›´é•·æœŸçš„è·Ÿè¹¤åˆ†æ")
    print("   - çµåˆå¤–éƒ¨å› ç´ ï¼ˆç«¶çˆ­ã€å­£ç¯€æ€§ç­‰ï¼‰é€²è¡Œæ·±å…¥åˆ†æ")
    print("   - å»ºç«‹å®šæœŸçš„å®šåƒ¹ç­–ç•¥è©•ä¼°æ©Ÿåˆ¶")

def demo_with_sample_data():
    """ä½¿ç”¨ç¤ºä¾‹æ•¸æ“šé€²è¡Œæ¼”ç¤º"""
    
    print("ğŸ¯ å‰µå»ºç¤ºä¾‹æ•¸æ“šé€²è¡Œæ¼”ç¤º...")
    
    # å‰µå»ºç¤ºä¾‹æ•¸æ“š
    sample_data = create_sample_real_data()
    
    # ä¿å­˜ç¤ºä¾‹æ•¸æ“š
    sample_data.to_csv('sample_pricing_data.csv', index=False, encoding='utf-8-sig')
    print("âœ… ç¤ºä¾‹æ•¸æ“šå·²ä¿å­˜åˆ° sample_pricing_data.csv")
    
    # å®šç¾©åˆ—åæ˜ å°„
    column_mapping = {
        'éŠ·å”®åƒ¹æ ¼': 'price',
        'éŠ·å”®æ•¸é‡': 'sales_volume',
        'è¨‚å–®æ—¥æœŸ': 'date',
        'å®¢æˆ¶ID': 'customer_id',
        'ç”¢å“ID': 'product_id'
    }
    
    # åŸ·è¡Œåˆ†æ
    analyzer, processed_data = analyze_real_data('sample_pricing_data.csv', column_mapping)
    
    return analyzer, processed_data

if __name__ == "__main__":
    # æ¼”ç¤ºåˆ†ææµç¨‹
    try:
        analyzer, data = demo_with_sample_data()
        print("\nğŸ‰ çœŸå¯¦æ•¸æ“šåˆ†ææ¼”ç¤ºå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ åˆ†æéç¨‹ä¸­å‡ºç¾éŒ¯èª¤: {e}")
        print("è«‹æª¢æŸ¥æ•¸æ“šæ ¼å¼å’Œåˆ—åæ˜ å°„æ˜¯å¦æ­£ç¢º")